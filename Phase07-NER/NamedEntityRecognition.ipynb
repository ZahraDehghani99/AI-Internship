{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NamedEntityRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pn7whCTPkkU"
      },
      "source": [
        "# Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khjvN4PmVAqZ",
        "outputId": "23368d53-552f-497f-8208-1292ffc35435"
      },
      "source": [
        "!pip install parsivar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.tar.gz (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 66 kB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n",
            "Building wheels for collected packages: parsivar, nltk\n",
            "  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsivar: filename=parsivar-0.2.3-py3-none-any.whl size=36492971 sha256=c11c14e5d4458c9258923835d20afd6de0e3040d198c6d72ff7a25eb1f64da52\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/67/7a/49cbf08f64d3f76a26eceaf0e481a40e233f05d4356875cbed\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=d6cc82a2f1169ef6bea91130fc15df0aab1fcb78a45906b913dd7fc193a52c73\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built parsivar nltk\n",
            "Installing collected packages: nltk, parsivar\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.4.5 parsivar-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPhHXBIWU3RV",
        "outputId": "30179463-ce61-4850-d426-7d240a42d2a0"
      },
      "source": [
        "# Loading NLTk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFLe5AaOVLO6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k54qImGUvoSX",
        "outputId": "20015627-d335-4cd7-f833-e7dcfd1939bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rU_bSwiVdky",
        "outputId": "57f356ac-343b-4f68-91a8-862ac02dcd5d"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "ex = 'my name is Ali and I live in Iran'\n",
        "entities = nltk.ne_chunk(pos_tag(word_tokenize(ex)))\n",
        "print(entities)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  my/PRP$\n",
            "  name/NN\n",
            "  is/VBZ\n",
            "  (PERSON Ali/NNP)\n",
            "  and/CC\n",
            "  I/PRP\n",
            "  live/VBP\n",
            "  in/IN\n",
            "  (GPE Iran/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQxsh5MaRry9"
      },
      "source": [
        "As we see, nltk can't recognize named entity in persian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHDTXAwkVdbm",
        "outputId": "09195357-6cff-4659-befb-ef458dda7a00"
      },
      "source": [
        "ex = 'من علی هستم و در ایران زندگی می کنم'\n",
        "entities = nltk.ne_chunk(pos_tag(word_tokenize(ex)))\n",
        "print(entities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  من/JJ\n",
            "  (ORGANIZATION علی/NNP)\n",
            "  هستم/NNP\n",
            "  و/NNP\n",
            "  در/NNP\n",
            "  ایران/NNP\n",
            "  زندگی/NNP\n",
            "  می/NNP\n",
            "  کنم/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM39miM1YTO9"
      },
      "source": [
        "## NER with lookup tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14NLQKBZLo4T"
      },
      "source": [
        "Let's do some exploratory on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofjTm_ifvifL"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/AI-Internship/country_list.csv', header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euBW9aPpL8ZG"
      },
      "source": [
        "As we see, our country list has one column. Each row consists of the Persian and English names of each country. This dataset is not in our desired form. So, we should split words in each row and separate them, then insert them into two new columns and delete the current column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ni6-5NZiwJHK",
        "outputId": "1aff3d31-0aee-4069-97ec-c2baa104d9ba"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1 'AFG' 'افغانستان'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 'ALA' 'جزایر آلند'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 'ALB' 'آلبانی'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 'DZA' 'الجزایر'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5 'ASM' 'ساموای آمریکا'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         0\n",
              "0      1 'AFG' 'افغانستان'\n",
              "1     2 'ALA' 'جزایر آلند'\n",
              "2         3 'ALB' 'آلبانی'\n",
              "3        4 'DZA' 'الجزایر'\n",
              "4  5 'ASM' 'ساموای آمریکا'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiSTpHciY8AH",
        "outputId": "87aa752d-3526-45a2-f65d-a49ee08e52d0"
      },
      "source": [
        "print(f'dataset shape : {df.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset shape : (244, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3sgBPXn5vuB",
        "outputId": "90eab633-ef66-43a2-cb68-67e0b6c4b591"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([0], dtype='int64')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nseML7n0QA2m"
      },
      "source": [
        "**Hint:** df[0][1] means first row of the column whose name is [0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr4zOFnU5fKk",
        "outputId": "f9b8490f-e21d-4274-fd1b-8e426dc3ae26"
      },
      "source": [
        "print(df[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 'AFG' 'افغانستان'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix4-K0wk5-Q6",
        "outputId": "99026e5d-3536-4ea9-d9c8-01906e95b530"
      },
      "source": [
        "df[0][0].split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', \"'AFG'\", \"'افغانستان'\"]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02bHk78eOQU4"
      },
      "source": [
        "Let's see another row in which the Persian name of that has more than one word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ1HJbRxz4kc",
        "outputId": "8c6aa61e-3be0-4550-c6dd-d6e96cfbcbf2"
      },
      "source": [
        "print(f'df[0][27] : {df[0][27]}')\n",
        "lst = df[0][27].split()[2:]\n",
        "print(f'country name : {lst}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df[0][27] : 28 'BIH' 'بوسنی و هرزگوین'\n",
            "country name : [\"'بوسنی\", 'و', \"هرزگوین'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h84JxNRPAuV"
      },
      "source": [
        "Let's combine the parts of this country name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uW7f2vVa1K-K",
        "outputId": "968b7bd4-b8ae-4a98-c0fd-66c92911f54e"
      },
      "source": [
        "lst = ' '.join(i for i in lst)\n",
        "lst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'بوسنی و هرزگوین'\""
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeX_y1supsRp"
      },
      "source": [
        "because we want to remove the first and end quotation we slice this string and use [1:-1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DdmDbHfSowCC",
        "outputId": "757e6d3d-86b6-4887-bc7c-2db1eb6bd822"
      },
      "source": [
        "lst[1:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'بوسنی و هرزگوین'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0DCNZ1YaH_u",
        "outputId": "f057a169-498a-49ec-d7f3-6227e2162fb1"
      },
      "source": [
        "en = []\n",
        "fa = []\n",
        "\n",
        "for i in range(df.shape[0]):\n",
        "  \n",
        "  row_splitted = df[0][i].split()\n",
        "  en.append(row_splitted[1][1:-1])\n",
        "  \n",
        "  name = row_splitted[2:]\n",
        "  name = ' '.join(word for word in name)\n",
        "  fa.append(name[1:-1])\n",
        "\n",
        "print(f'10 elements of en : {en[:10]}')\n",
        "print(f'10 elements of fa : {fa[:10]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 elements of en : ['AFG', 'ALA', 'ALB', 'DZA', 'ASM', 'AND', 'AGO', 'AIA', 'ATA', 'ATG']\n",
            "10 elements of fa : ['افغانستان', 'جزایر آلند', 'آلبانی', 'الجزایر', 'ساموای آمریکا', 'آندورا', 'آنگولا', 'آنگویلا', 'جنوبگان', 'آنتیگوا و باربودا']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGFy5HGwbMKN"
      },
      "source": [
        "Let's insert two columns to the country dataframe.One for english name of countrie and another for persian name of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO5gXbH_ZuGN"
      },
      "source": [
        "country = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVyCHlVWZym4"
      },
      "source": [
        "country.insert(1, \"en\", en)\n",
        "country.insert(2, \"fa\", fa)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aaIyNgxI6FYj",
        "outputId": "cf15e733-1436-40fe-b863-2fb4f44218ad"
      },
      "source": [
        "country.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>en</th>\n",
              "      <th>fa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1 'AFG' 'افغانستان'</td>\n",
              "      <td>AFG</td>\n",
              "      <td>افغانستان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 'ALA' 'جزایر آلند'</td>\n",
              "      <td>ALA</td>\n",
              "      <td>جزایر آلند</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 'ALB' 'آلبانی'</td>\n",
              "      <td>ALB</td>\n",
              "      <td>آلبانی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 'DZA' 'الجزایر'</td>\n",
              "      <td>DZA</td>\n",
              "      <td>الجزایر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5 'ASM' 'ساموای آمریکا'</td>\n",
              "      <td>ASM</td>\n",
              "      <td>ساموای آمریکا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         0   en             fa\n",
              "0      1 'AFG' 'افغانستان'  AFG      افغانستان\n",
              "1     2 'ALA' 'جزایر آلند'  ALA     جزایر آلند\n",
              "2         3 'ALB' 'آلبانی'  ALB         آلبانی\n",
              "3        4 'DZA' 'الجزایر'  DZA        الجزایر\n",
              "4  5 'ASM' 'ساموای آمریکا'  ASM  ساموای آمریکا"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy-Ou7v3Zkqq"
      },
      "source": [
        "country.drop([0], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LqR5LkB9c_S7",
        "outputId": "a9e233b1-ae48-4719-dd4a-dcfb4d9a4da5"
      },
      "source": [
        "country.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AFG</td>\n",
              "      <td>افغانستان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALA</td>\n",
              "      <td>جزایر آلند</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ALB</td>\n",
              "      <td>آلبانی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DZA</td>\n",
              "      <td>الجزایر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ASM</td>\n",
              "      <td>ساموای آمریکا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    en             fa\n",
              "0  AFG      افغانستان\n",
              "1  ALA     جزایر آلند\n",
              "2  ALB         آلبانی\n",
              "3  DZA        الجزایر\n",
              "4  ASM  ساموای آمریکا"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PJDC9aj8RYCE",
        "outputId": "1ae1616a-d617-4a0c-896c-bc49d7f66249"
      },
      "source": [
        "country.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>WLF</td>\n",
              "      <td>والیس و فوتونا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>ESH</td>\n",
              "      <td>صحرای غربی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>YEM</td>\n",
              "      <td>یمن</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>ZMB</td>\n",
              "      <td>زامبیا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>ZWE</td>\n",
              "      <td>زیمبابوه'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      en              fa\n",
              "239  WLF  والیس و فوتونا\n",
              "240  ESH      صحرای غربی\n",
              "241  YEM             یمن\n",
              "242  ZMB          زامبیا\n",
              "243  ZWE       زیمبابوه'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p-OeLaCRvo9"
      },
      "source": [
        "As wee see, last row is not in right way, so we should correct it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUKKHOMeRhrX"
      },
      "source": [
        "country.fa[243] = country.fa[243][:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gm1wnsY5R71d",
        "outputId": "666d4e88-ee6f-4ac4-e931-c0559a7fcdcf"
      },
      "source": [
        "country.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>WLF</td>\n",
              "      <td>والیس و فوتونا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>ESH</td>\n",
              "      <td>صحرای غربی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>YEM</td>\n",
              "      <td>یمن</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>ZMB</td>\n",
              "      <td>زامبیا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>ZWE</td>\n",
              "      <td>زیمبابوه</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      en              fa\n",
              "239  WLF  والیس و فوتونا\n",
              "240  ESH      صحرای غربی\n",
              "241  YEM             یمن\n",
              "242  ZMB          زامبیا\n",
              "243  ZWE        زیمبابوه"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEta7Y4odCYD"
      },
      "source": [
        "# #Save dataframe\n",
        "# country.to_pickle('/content/drive/MyDrive/AI-Internship/country_lookup')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWHyO3Zcdp5J"
      },
      "source": [
        "#load the preprocessing dataframe\n",
        "country = pd.read_pickle(r'/content/drive/MyDrive/AI-Internship/country_lookup')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsjO5zP6d01f",
        "outputId": "eee851e3-e92b-42f1-929e-9837cdac70c1"
      },
      "source": [
        "country.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(244, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hq9iGlzSPuS",
        "outputId": "e576c811-7d65-4614-97d6-4d86aad0760f"
      },
      "source": [
        "country.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "en    0\n",
              "fa    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u0HxQADSXvo",
        "outputId": "6d3ba319-9707-45f8-916f-a13ebd80d001"
      },
      "source": [
        "country.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 244 entries, 0 to 243\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   en      244 non-null    object\n",
            " 1   fa      244 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZQ9CGmeTAje"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo-XNKG_q3rq"
      },
      "source": [
        "Let's develop NER with lookup tables.\n",
        "If our sentece has some of the words in lookup tabel, this model recognize it and asign it to the predifined category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEcsqbc5enet"
      },
      "source": [
        "def lookup_model(sentence):\n",
        "  \n",
        "  result = []\n",
        "  for name in country.fa.values:\n",
        "    if name in sentence:\n",
        "      result += [('GRE', name)]\n",
        "  return result    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEV8slZtapQr"
      },
      "source": [
        "Let's perform this model on some examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAnKHdjInwi-",
        "outputId": "49c16b2e-03d3-42c9-9b28-29b69af63362"
      },
      "source": [
        "print(lookup_model('من علی هستم و در ایران زندکی می کنم'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('GRE', 'ایران')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nDEBDQMY12q",
        "outputId": "3d71fbfd-2e83-4929-ac54-3b57e71637ed"
      },
      "source": [
        "print(lookup_model('.من برای تعطیلات به جزیره هرد و جزایر مک زیبا خواهم رفت'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('GRE', 'جزیره هرد و جزایر مک')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkX4fo-DvPdw",
        "outputId": "f78bc5c1-1ebb-4a2b-935a-26bd5d724fb6"
      },
      "source": [
        "print(lookup_model('تعداد دانشجویان ایرانی  که به کانادا مهاجرت می کنند روز به روز بیشتر می شود.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('GRE', 'کانادا'), ('GRE', 'ایران')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpkhXtVjPbA"
      },
      "source": [
        "## NER With Regex "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZma2pvUXmPC"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bMUMHDuCPlw"
      },
      "source": [
        "If the sentence has specific words like \"کشور\", this model recognize the word after this word as a country(or other related category.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcSbwleRwxJv"
      },
      "source": [
        "import re\n",
        "\n",
        "def regex_model(sentence):\n",
        "\n",
        "  result = []\n",
        "  iter = re.finditer(r\"\\bکشور\\b\", sentence)\n",
        "  indices = [m.end(0) for m in iter]\n",
        "  \n",
        "  for i in indices:\n",
        "    result.append(('GRE', sentence[i+1:sentence[i+1:].find(\" \")+ (i+1)]))\n",
        "  return result  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrGxDOlqnxNw"
      },
      "source": [
        "sentence = 'من در کشور ایران زندگی میکنم. من کشور خود را دوست دارم. من کشورم ایران را دوست دارم. او برای سفر به کشور جمهوری چک می رود.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9WibrK5xCmR",
        "outputId": "39cbc319-3dda-4ecd-cd24-a5ca18ed8d0e"
      },
      "source": [
        "print(regex_model(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('GRE', 'ایران'), ('GRE', 'خود'), ('GRE', 'جمهوری')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovuWBnL6oB4e"
      },
      "source": [
        "## Regex look behind\n",
        "# ind = re.search('(?<=کشور )(\\w+)', sentence).groups()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXnll8FW0GUS"
      },
      "source": [
        "# ???????????? lookup and regex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9NNyruvB1i7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LOqZjDpXaS9"
      },
      "source": [
        "## NER With Stanford NER and NLTK "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b85HHLFKYJLg"
      },
      "source": [
        "###Implementing NER with Stanford NER / NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZSjeqvpXqAh"
      },
      "source": [
        "Because Stanford NER tagger is written in Java, you are going to need a proper Java Virtual Machine to be installed on your computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r5iWlj6XJYm",
        "outputId": "32b56657-bc11-43c8-8cdd-cf133f6c5a97"
      },
      "source": [
        "import os       #importing os to set environment variable\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.11\" 2021-04-20\n",
            "OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqZHmixxvTY-"
      },
      "source": [
        "Let's download Stanford NER model from https://nlp.stanford.edu/software/CRF-NER.html and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liFxS7PxX-ap"
      },
      "source": [
        "# import zipfile\n",
        "# # unzip image file\n",
        "# local_zip = '/content/drive/MyDrive/AI-Internship/stanford-ner-4.2.0.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('/content/drive/MyDrive/AI-Internship/stanford-ner-4.2.0')\n",
        "# zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndmjV4KzBT0A"
      },
      "source": [
        "After unzipping this file, we need two things of this folder.(stanford-ner-4.2.0.jar and our model: english.all.3class.distsim.crf.ser.gz)\n",
        "\n",
        "First we should create a folder in our drive, whose name is 'stanford-ner-tagger'. Then put .jar and .gz in this folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJT4C-q4J8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebc552b-2980-4170-dce6-515f3343d699"
      },
      "source": [
        "import nltk\n",
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "\n",
        "jar = '/content/drive/MyDrive/AI-Internship/stanford-ner-tagger/stanford-ner-4.2.0.jar'\n",
        "model = '/content/drive/MyDrive/AI-Internship/stanford-ner-tagger/english.all.3class.distsim.crf.ser.gz'\n",
        "\n",
        "sentence = u\"Twenty miles east of Reno, Nev., \" \\\n",
        "    \"where packs of wild mustangs roam free through \" \\\n",
        "    \"the parched landscape, Tesla Gigafactory 1 \" \\\n",
        "    \"sprawls near Interstate 80.\"\n",
        "\n",
        "# prepare NER tagger with english model\n",
        "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
        "\n",
        "# tokenize: split sentece into words\n",
        "words = nltk.word_tokenize(sentence)\n",
        "\n",
        "# run NER tagger on words\n",
        "print(ner_tagger.tag(words))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Twenty', 'O'), ('miles', 'O'), ('east', 'O'), ('of', 'O'), ('Reno', 'LOCATION'), (',', 'O'), ('Nev.', 'LOCATION'), (',', 'O'), ('where', 'O'), ('packs', 'O'), ('of', 'O'), ('wild', 'O'), ('mustangs', 'O'), ('roam', 'O'), ('free', 'O'), ('through', 'O'), ('the', 'O'), ('parched', 'O'), ('landscape', 'O'), (',', 'O'), ('Tesla', 'ORGANIZATION'), ('Gigafactory', 'ORGANIZATION'), ('1', 'O'), ('sprawls', 'O'), ('near', 'O'), ('Interstate', 'LOCATION'), ('80', 'LOCATION'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5zBdzGxB7uh"
      },
      "source": [
        "As we can see, our model in not bad. It recognize some of named entity. But this model traind just on english corpus, so we should train our own model on the desired language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hVwiWYtYWcM"
      },
      "source": [
        "### Training our own (Persian) model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w16Ant-RBMpJ"
      },
      "source": [
        "In this section, we should train our own model with our dataset.\n",
        "\n",
        "Our dataset should be in a proper format (each row has just a word and its role and in each row, firs column is word and another one is role of this word.)\n",
        "\n",
        "We should create 'train' folder in 'stanford-ner-tagger' folder. Then we put our dataset in it.\n",
        "\n",
        "At this moment we should wire some properties like our model directory, our train file directory and ... in text file whose name is 'prop.txt' and we put it in 'train' folder.\n",
        "\n",
        "The format of our prop.txt file is as follow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL0Vp3djT5sU"
      },
      "source": [
        "# trainFile = train/persian NER/train.txt\n",
        "# serializeTo = dummy-ner-model-persian.ser.gz\n",
        "\n",
        "# #structure of your training file; this tells the classifier\n",
        "# #that the word is in column 0 and the correct answer is in\n",
        "# #column 1\n",
        "\n",
        "# map = word=0,answer=1\n",
        "\n",
        "# useClassFeature=true\n",
        "# useWord=true\n",
        "# useNGrams=true\n",
        "# noMidNGrams=true\n",
        "# maxNGramLeng=6\n",
        "# usePrev=true\n",
        "# useNext=true\n",
        "# useSequences=true\n",
        "# usePrevSequences=true\n",
        "# maxLeft=1\n",
        "# useTypeSeqs=true\n",
        "# useTypeSeqs2=true\n",
        "# useTypeySequences=true\n",
        "# wordShape=chris2useLC\n",
        "# useDisjunctive=true"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jenAY443G46g"
      },
      "source": [
        "Train it, using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AskaSCL2zF_",
        "outputId": "58637177-289b-471a-893c-f70b4f4912fa"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/AI-Internship/stanford-ner-tagger/\"\n",
        "!java -cp \"stanford-ner-4.2.0.jar:lib/*\" -mx4g edu.stanford.nlp.ie.crf.CRFClassifier -prop train/prop.txt"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI-Internship/stanford-ner-tagger\n",
            "Invoked on Sun Sep 19 09:01:13 UTC 2021 with arguments: -prop train/prop.txt\n",
            "useTypeSeqs2=true\n",
            "noMidNGrams=true\n",
            "trainFile=train/train.tsv\n",
            "maxNGramLeng=6\n",
            "maxLeft=1\n",
            "serializeTo=dummy-ner-model-persian.ser.gz\n",
            "wordShape=chris2useLC\n",
            "useDisjunctive=true\n",
            "useClassFeature=true\n",
            "useNGrams=true\n",
            "useNext=true\n",
            "usePrev=true\n",
            "useTypeySequences=true\n",
            "usePrevSequences=true\n",
            "qnSize=10\n",
            "useTypeSeqs=true\n",
            "useSequences=true\n",
            "map=word=0,answer=1\n",
            "useWord=true\n",
            "numFeatures = 1232256\n",
            "Time to convert docs to feature indices: 18.3 seconds\n",
            "Current memory used: 497m\n",
            "numClasses: 13 [0=O,1=B-pers,2=B-event,3=I-event,4=I-pers,5=B-loc,6=I-loc,7=B-pro,8=I-pro,9=B-fac,10=I-fac,11=B-org,12=I-org]\n",
            "numDocuments: 10241\n",
            "numDatums: 334734\n",
            "numFeatures: 1232256\n",
            "Time to convert docs to data/labels: 9.1 seconds\n",
            "Current memory used: 701m\n",
            "Running gradient on 2 threads\n",
            "numWeights: 71140524\n",
            "QNMinimizer called on double function of 71140524 variables, using M = 10.\n",
            "Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n",
            "\tat edu.stanford.nlp.optimization.QNMinimizer.minimize(QNMinimizer.java:903)\n",
            "\tat edu.stanford.nlp.optimization.QNMinimizer.minimize(QNMinimizer.java:871)\n",
            "\tat edu.stanford.nlp.optimization.QNMinimizer.minimize(QNMinimizer.java:865)\n",
            "\tat edu.stanford.nlp.optimization.QNMinimizer.minimize(QNMinimizer.java:93)\n",
            "\tat edu.stanford.nlp.ie.crf.CRFClassifier.trainWeights(CRFClassifier.java:1879)\n",
            "\tat edu.stanford.nlp.ie.crf.CRFClassifier.train(CRFClassifier.java:1684)\n",
            "\tat edu.stanford.nlp.ie.AbstractSequenceClassifier.train(AbstractSequenceClassifier.java:774)\n",
            "\tat edu.stanford.nlp.ie.AbstractSequenceClassifier.train(AbstractSequenceClassifier.java:762)\n",
            "\tat edu.stanford.nlp.ie.crf.CRFClassifier.main(CRFClassifier.java:2967)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjDO_OUv-d6R",
        "outputId": "ee5dffb2-74c2-4ad2-cc11-6349c147fd3e"
      },
      "source": [
        "!df -h"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   45G   64G  41% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.9G     0  5.9G   0% /dev/shm\n",
            "tmpfs           6.4G   28K  6.4G   1% /var/colab\n",
            "/dev/sda1        81G   49G   33G  60% /etc/hosts\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "drive            15G   11G  4.1G  73% /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsUmxUe2Omzz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}